{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg1KHQw-8pWo",
    "outputId": "8450df9d-e34e-4e42-8417-005d781014c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vecstack in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vecstack) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vecstack) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vecstack) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "  Using cached torch-2.4.1-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ranji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached torch-2.4.1-cp312-cp312-win_amd64.whl (199.4 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.1+cu124 requires torch==2.4.1+cu124, but you have torch 2.4.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "!pip install vecstack\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O1xc-QWKIQL2"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from vecstack import stacking\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzEmFcytFcfe",
    "outputId": "63e68564-2419-4d9a-bdf5-96005aa6137c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p5pWkxcQIZ9y"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv('RevisedHomesiteTrain1.csv')\n",
    "test_data = pd.read_csv('RevisedHomesiteTest1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df4Z71W0IWVX",
    "outputId": "06f92e56-f595-4cf7-fe77-2eb5250d8e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data after one-hot encoding: (65000, 599)\n",
      "Shape of test data after one-hot encoding: (173836, 599)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "X_train = train_data.drop(['QuoteConversion_Flag'], axis=1)  # Replace 'target' with the name of the target column\n",
    "y_train = train_data['QuoteConversion_Flag']\n",
    "\n",
    "# one-hot encoded - Convert categorical variables into dummy/indicator variables\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(test_data)\n",
    "\n",
    "# Align columns in X_train and X_test to ensure consistency\n",
    "X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n",
    "\n",
    "# Print the shape of encoded data\n",
    "print(\"Shape of training data after one-hot encoding:\", X_train.shape)\n",
    "print(\"Shape of test data after one-hot encoding:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mFQXMkchJaNc"
   },
   "outputs": [],
   "source": [
    "# Define the models\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "svc = LinearSVC(random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "c0Ym-MU3JufF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_Data_MLP.csv\n",
      "Predictions saved to prediction_Data_Decision Tree.csv\n",
      "Predictions saved to prediction_Data_Random Forest.csv\n",
      "Predictions saved to prediction_Data_KNN.csv\n",
      "Predictions saved to prediction_Data_Linear SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# Train the models individually\n",
    "models = [mlp, dt, rf, knn, svc]\n",
    "model_names = ['MLP', 'Decision Tree', 'Random Forest', 'KNN','Linear SVM']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    # Fit the model and Predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    prediction_df = pd.DataFrame({'QuoteNumber': X_test['QuoteNumber'], 'QuoteConversion_Flag': y_pred})\n",
    "    file_name = f'prediction_Data_{name}.csv'\n",
    "    prediction_df.to_csv(file_name, index=False)\n",
    "    print(f\"Predictions saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwD8P1YO9P4T",
    "outputId": "c73bb930-7a16-450e-d550-c3448035039d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      "Class distribution in training set: QuoteConversion_Flag\n",
      "0    52738\n",
      "1    12262\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      "Class distribution in training set: QuoteConversion_Flag\n",
      "0    52738\n",
      "1    31642\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print class distribution before SMOTE\n",
    "print(\"Before SMOTE:\")\n",
    "print(\"Class distribution in training set:\", y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE for oversampling the minority class\n",
    "smote = SMOTE(sampling_strategy=0.6, random_state=42)  # Adjust percentage as needed\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print class distribution after SMOTE\n",
    "print(\"After SMOTE:\")\n",
    "print(\"Class distribution in training set:\", y_train_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZaLptOx9P7E",
    "outputId": "5436b25b-1971-4278-ab51-42f414558d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [MLPClassifier]\n",
      "    fold  0:  [0.88248400]\n",
      "    fold  1:  [0.77435411]\n",
      "    fold  2:  [0.79530694]\n",
      "    fold  3:  [0.86082010]\n",
      "    ----\n",
      "    MEAN:     [0.82824129] + [0.04469941]\n",
      "    FULL:     [0.82824129]\n",
      "\n",
      "model  1:     [LinearSVC]\n",
      "    fold  0:  [0.88656080]\n",
      "    fold  1:  [0.89224935]\n",
      "    fold  2:  [0.90727661]\n",
      "    fold  3:  [0.90926760]\n",
      "    ----\n",
      "    MEAN:     [0.89883859] + [0.00967118]\n",
      "    FULL:     [0.89883859]\n",
      "\n",
      "model  2:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.90286798]\n",
      "    fold  1:  [0.90590187]\n",
      "    fold  2:  [0.90334202]\n",
      "    fold  3:  [0.90040294]\n",
      "    ----\n",
      "    MEAN:     [0.90312870] + [0.00195152]\n",
      "    FULL:     [0.90312870]\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    fold  0:  [0.92562219]\n",
      "    fold  1:  [0.92543257]\n",
      "    fold  2:  [0.92789761]\n",
      "    fold  3:  [0.92472150]\n",
      "    ----\n",
      "    MEAN:     [0.92591846] + [0.00119097]\n",
      "    FULL:     [0.92591846]\n",
      "\n",
      "model  4:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.69547286]\n",
      "    fold  1:  [0.69646836]\n",
      "    fold  2:  [0.68968950]\n",
      "    fold  3:  [0.68897843]\n",
      "    ----\n",
      "    MEAN:     [0.69265229] + [0.00334639]\n",
      "    FULL:     [0.69265229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models=[mlp, svc, dt, rf, knn],\n",
    "    X_train=X_train_smote,\n",
    "    y_train=y_train_smote,\n",
    "    X_test=X_test,\n",
    "    regression=False,\n",
    "    mode='oof_pred_bag',\n",
    "    needs_proba=False,\n",
    "    save_dir=None,\n",
    "    metric=accuracy_score,\n",
    "    n_folds=4,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkIxftkz9P9m"
   },
   "outputs": [],
   "source": [
    "#STACKING - CONTRUCT A GRADIENT BOOSTING MODEL\n",
    "meta_model = GradientBoostingClassifier(random_state=42)\n",
    "stacking_clf = meta_model.fit(S_train, y_train_smote)\n",
    "y_pred_val_stack  = stacking_clf.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Q7T9LTVYuMD",
    "outputId": "ddd67b3f-02a4-40b1-b20b-d873d1c65adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_Data.csv\n"
     ]
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame({'QuoteNumber': X_test['QuoteNumber'], 'QuoteConversion_Flag': y_pred_val_stack})\n",
    "\n",
    "# Store y_test_pred to data file\n",
    "file_name = f'prediction_Data.csv'\n",
    "prediction_df.to_csv(file_name, index=False)\n",
    "print(f\"Predictions saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SPvTfEb9QAi",
    "outputId": "2b9ee0de-6b01-4b4c-9f72-1c7a02642e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Best parameters for the stacked model: GradientBoostingClassifier(learning_rate=0.01, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning - Define the parameter grid for the meta-model\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters for the meta-model\n",
    "grid_search = GridSearchCV(stacking_clf, param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(S_train, y_train_smote)\n",
    "\n",
    "# Get the best meta-model\n",
    "best_meta_model = grid_search.best_estimator_\n",
    "print(\"Best parameters for the stacked model:\", best_meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wyhxXurA1K8",
    "outputId": "47c69601-33cc-4cd6-a263-c622a0ab30ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_Data_tuned.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the stacked model\n",
    "y_pred_val_stack_tuned = best_meta_model.predict(S_test)\n",
    "\n",
    "prediction_df = pd.DataFrame({'QuoteNumber': X_test['QuoteNumber'], 'QuoteConversion_Flag': y_pred_val_stack_tuned})\n",
    "\n",
    "# Store y_test_pred to data file\n",
    "file_name = f'prediction_Data_tuned.csv'\n",
    "prediction_df.to_csv(file_name, index=False)\n",
    "print(f\"Predictions saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWKUSdQgwyiB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
