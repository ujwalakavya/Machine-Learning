{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-genetic\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9IIOZoJrj0F",
        "outputId": "cd7a7776-c940-4ccb-d39a-05cf795f9ddc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-genetic\n",
            "  Downloading sklearn_genetic-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic) (1.5.2)\n",
            "Collecting deap>=1.0.2 (from sklearn-genetic)\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic) (1.26.4)\n",
            "Collecting multiprocess (from sklearn-genetic)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->sklearn-genetic) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->sklearn-genetic) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->sklearn-genetic) (3.5.0)\n",
            "Collecting dill>=0.3.9 (from multiprocess->sklearn-genetic)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading sklearn_genetic-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, deap, multiprocess, sklearn-genetic\n",
            "Successfully installed deap-1.4.1 dill-0.3.9 multiprocess-0.70.17 sklearn-genetic-0.6.0\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oWCkntyjGhWg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
        "from genetic_selection import GeneticSelectionCV\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "from google.colab import drive # Load data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Masters/ML/train_house.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Masters/ML/test_House.csv')"
      ],
      "metadata": {
        "id": "pefpVStUEbAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0bcf5b-28e1-461f-802b-622645b7d6ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "id": "1qcUHNDFFK1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "299bebd3-a0f8-479b-f7c3-d47bd9cd8a61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
              "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
              "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
              "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
              "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
              "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
              "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
              "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
              "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
              "\n",
              "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
              "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
              "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
              "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
              "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
              "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
              "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
              "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
              "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0af57f14-50db-4daa-b426-c9c0da0f8436\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0af57f14-50db-4daa-b426-c9c0da0f8436')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0af57f14-50db-4daa-b426-c9c0da0f8436 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0af57f14-50db-4daa-b426-c9c0da0f8436');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-841d31dc-8659-4707-b567-87c9ce06e6c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-841d31dc-8659-4707-b567-87c9ce06e6c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-841d31dc-8659-4707-b567-87c9ce06e6c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "HUghfh12FNup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c817d7-f6be-46f8-e17a-4c45e9e30c43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 81)\n",
            "(1459, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "id": "9MWHU2YqFPcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aadb34d-a159-4674-9685-6d22a51e6731"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      259\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pPzmADiEiEuG"
      },
      "outputs": [],
      "source": [
        "# Assume target variable is \"SalePrice\" in train data\n",
        "X_train_full = train_data.drop(\"SalePrice\", axis=1)\n",
        "y_train_full = train_data[\"SalePrice\"]\n",
        "X_test_full = test_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numeric and categorical features\n",
        "numeric_features = X_train_full.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X_train_full.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "WNRlllswE4a6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into train/validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bXZ8-1Y-EmFY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Support Vector Regressor\": SVR(),\n",
        "    \"MLP Regressor\": MLPRegressor(random_state=42, max_iter=1000),\n",
        "    \"SGD Regressor\": SGDRegressor(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "gxdCZESTEmI5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('regressor', model)])\n",
        "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
        "    results[name] = -np.mean(scores)"
      ],
      "metadata": {
        "id": "x3qhzNDfGg6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccce6b79-cdfc-4b22-b059-301177221bf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Ensemble\n",
        "class StackingModel(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, models, meta_model):\n",
        "        self.models = models\n",
        "        self.meta_model = meta_model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_instances = []\n",
        "        for name, model in self.models.items():\n",
        "            pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                        ('regressor', model)])\n",
        "            pipeline.fit(X, y)\n",
        "            self.model_instances.append((name, pipeline))\n",
        "\n",
        "        # Generate meta features\n",
        "        meta_features = np.column_stack([model.predict(X) for _, model in self.model_instances])\n",
        "        self.meta_model.fit(meta_features, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([model.predict(X) for _, model in self.model_instances])\n",
        "        return self.meta_model.predict(meta_features)\n",
        "\n",
        "stacked_model = StackingModel(models=models, meta_model=LinearRegression())\n",
        "stacked_model.fit(X_train, y_train)\n",
        "stacked_predictions = stacked_model.predict(X_val)\n",
        "stacked_rmse = mean_squared_error(y_val, stacked_predictions, squared=False)\n",
        "results[\"Stacked Model\"] = stacked_rmse"
      ],
      "metadata": {
        "id": "gkwM-sEZGg80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c3f40e-7ca2-4a85-b4a8-20ebbaaeda47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Predict on Test Data\n",
        "stacked_test_predictions = stacked_model.predict(X_test_full)\n",
        "\n",
        "# Save Predictions\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": X_test_full[\"Id\"],\n",
        "    \"SalePrice\": stacked_test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission_Stacked_Ujwala.csv\", index=False)"
      ],
      "metadata": {
        "id": "NK7VIVc1Gg_N"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Optimized parameter distributions for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    \"Random Forest\": {\n",
        "        \"regressor__n_estimators\": randint(50, 150),\n",
        "        \"regressor__max_depth\": [10, 15, None]\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"regressor__max_depth\": [10, 15, None],\n",
        "        \"regressor__min_samples_split\": randint(2, 10)\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"regressor__n_estimators\": randint(50, 150),\n",
        "        \"regressor__learning_rate\": uniform(0.05, 0.15)\n",
        "    },\n",
        "    \"Support Vector Regressor\": {\n",
        "        \"regressor__C\": uniform(0.1, 5),\n",
        "        \"regressor__epsilon\": uniform(0.01, 0.1),\n",
        "        \"regressor__kernel\": [\"linear\", \"rbf\"]\n",
        "    },\n",
        "    \"MLP Regressor\": {\n",
        "        \"regressor__hidden_layer_sizes\": [(50,), (100,)],\n",
        "        \"regressor__alpha\": uniform(0.0001, 0.01),\n",
        "        \"regressor__learning_rate\": [\"constant\", \"adaptive\"]\n",
        "    },\n",
        "    \"SGD Regressor\": {\n",
        "        \"regressor__alpha\": uniform(0.0001, 0.01),\n",
        "        \"regressor__penalty\": [\"l2\", \"elasticnet\"],\n",
        "        \"regressor__max_iter\": randint(1000, 2000)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Dictionary to store tuned models\n",
        "tuned_models = {}\n",
        "\n",
        "# Perform hyperparameter tuning for each model, predict on test data, and save results\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
        "\n",
        "    # Check if parameter distributions are defined for the model\n",
        "    if name in param_distributions:\n",
        "        print(f\"Tuning hyperparameters for {name} using RandomizedSearchCV...\")\n",
        "        random_search = RandomizedSearchCV(\n",
        "            pipeline,\n",
        "            param_distributions=param_distributions[name],\n",
        "            n_iter=20,\n",
        "            cv=2,\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "        random_search.fit(X_train, y_train)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(f\"Best parameters for {name}: {random_search.best_params_}\")\n",
        "        tuned_models[name] = best_model  # Save the tuned model\n",
        "    else:\n",
        "        print(f\"No hyperparameter tuning defined for {name}, using default parameters.\")\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        tuned_models[name] = pipeline  # Save the default model\n",
        "\n",
        "    # Predict on test data\n",
        "    test_predictions = tuned_models[name].predict(X_test_full)\n",
        "\n",
        "    # Save predictions to a CSV file\n",
        "    submission = pd.DataFrame({\n",
        "        \"Id\": X_test_full[\"Id\"],\n",
        "        \"SalePrice\": test_predictions\n",
        "    })\n",
        "    submission_file = f\"submission_{name.replace(' ', '_')}.csv\"\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Predictions for {name} saved to {submission_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnHwIkPhGiNg",
        "outputId": "be9c714d-5b53-4714-d5fb-d60e14524e90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning hyperparameters for Random Forest using RandomizedSearchCV...\n",
            "Best parameters for Random Forest: {'regressor__max_depth': 15, 'regressor__n_estimators': 113}\n",
            "Predictions for Random Forest saved to submission_Random_Forest.csv\n",
            "Tuning hyperparameters for Decision Tree using RandomizedSearchCV...\n",
            "Best parameters for Decision Tree: {'regressor__max_depth': None, 'regressor__min_samples_split': 4}\n",
            "Predictions for Decision Tree saved to submission_Decision_Tree.csv\n",
            "Tuning hyperparameters for Gradient Boosting using RandomizedSearchCV...\n",
            "Best parameters for Gradient Boosting: {'regressor__learning_rate': 0.17992642186624025, 'regressor__n_estimators': 149}\n",
            "Predictions for Gradient Boosting saved to submission_Gradient_Boosting.csv\n",
            "Tuning hyperparameters for Support Vector Regressor using RandomizedSearchCV...\n",
            "Best parameters for Support Vector Regressor: {'regressor__C': 5.016154429033941, 'regressor__epsilon': 0.056676289324798, 'regressor__kernel': 'linear'}\n",
            "Predictions for Support Vector Regressor saved to submission_Support_Vector_Regressor.csv\n",
            "Tuning hyperparameters for MLP Regressor using RandomizedSearchCV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for MLP Regressor: {'regressor__alpha': 0.0003058449429580245, 'regressor__hidden_layer_sizes': (100,), 'regressor__learning_rate': 'adaptive'}\n",
            "Predictions for MLP Regressor saved to submission_MLP_Regressor.csv\n",
            "Tuning hyperparameters for SGD Regressor using RandomizedSearchCV...\n",
            "Best parameters for SGD Regressor: {'regressor__alpha': 0.007419939418114052, 'regressor__max_iter': 1700, 'regressor__penalty': 'l2'}\n",
            "Predictions for SGD Regressor saved to submission_SGD_Regressor.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter tuned models to use only Gradient Boosting, Random Forest, and SGD Regressor\n",
        "base_models_tuned = {\n",
        "    \"Gradient Boosting\": tuned_models[\"Gradient Boosting\"],\n",
        "    \"Random Forest\": tuned_models[\"Random Forest\"],\n",
        "    \"SGD Regressor\": tuned_models[\"SGD Regressor\"]\n",
        "}\n",
        "\n",
        "# Define and tune the meta-model using Optuna\n",
        "class StackingModel(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, models, meta_model):\n",
        "        self.models = models\n",
        "        self.meta_model = meta_model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model_instances = []\n",
        "        meta_features = []\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.fit(X, y)\n",
        "            self.model_instances.append((name, model))\n",
        "            meta_features.append(model.predict(X))\n",
        "\n",
        "        self.meta_features_train = np.column_stack(meta_features)\n",
        "        self.meta_model.fit(self.meta_features_train, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            model.predict(X) for _, model in self.model_instances\n",
        "        ])\n",
        "        return self.meta_model.predict(meta_features)\n",
        "\n",
        "# Define Optuna objective function for meta-model tuning\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.05, 0.2)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "\n",
        "    meta_model = GradientBoostingRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Build the stacking model using only the selected base models\n",
        "    stacked_model = StackingModel(models=base_models_tuned, meta_model=meta_model)\n",
        "    stacked_model.fit(X_train, y_train)\n",
        "\n",
        "    # Validate the stacking model\n",
        "    stacked_predictions = stacked_model.predict(X_val)\n",
        "    stacked_rmse = mean_squared_error(y_val, stacked_predictions, squared=False)\n",
        "    return stacked_rmse\n",
        "\n",
        "# Perform Optuna optimization for the meta-model\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Best meta-model parameters\n",
        "best_params = study.best_params\n",
        "print(f\"Best parameters for the meta-model: {best_params}\")\n",
        "\n",
        "# Final Stacking Model with the best meta-model\n",
        "best_meta_model = GradientBoostingRegressor(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    random_state=42\n",
        ")\n",
        "stacked_model = StackingModel(models=base_models_tuned, meta_model=best_meta_model)\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "# Validate the stacked model\n",
        "stacked_predictions = stacked_model.predict(X_val)\n",
        "stacked_rmse = mean_squared_error(y_val, stacked_predictions, squared=False)\n",
        "print(f\"Stacked Model RMSE: {stacked_rmse}\")\n",
        "\n",
        "# Predict on test data\n",
        "stacked_test_predictions = stacked_model.predict(X_test_full)\n",
        "\n",
        "# Save predictions\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": X_test_full[\"Id\"],  # Replace 'Id' with the test set identifier column\n",
        "    \"SalePrice\": stacked_test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission_Stacked_Optimized.csv\", index=False)\n",
        "print(\"Predictions saved to submission_Stacked_Optimized.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WCQFXWEPOjaS",
        "outputId": "5126730c-ff51-4595-94de-f471d48daed1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-27 02:10:56,256] A new study created in memory with name: no-name-b1120939-9f87-4efe-93d8-c3348f8a550d\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:11:11,809] Trial 0 finished with value: 28250.625756376216 and parameters: {'n_estimators': 189, 'learning_rate': 0.13945919992062672, 'max_depth': 6, 'min_samples_split': 10}. Best is trial 0 with value: 28250.625756376216.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:11:30,772] Trial 1 finished with value: 29378.488525274497 and parameters: {'n_estimators': 109, 'learning_rate': 0.18761679085356003, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 0 with value: 28250.625756376216.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:11:47,733] Trial 2 finished with value: 28041.83268967458 and parameters: {'n_estimators': 116, 'learning_rate': 0.1978534863710552, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: 28041.83268967458.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:12:02,756] Trial 3 finished with value: 28236.076041042645 and parameters: {'n_estimators': 67, 'learning_rate': 0.1962626126772305, 'max_depth': 3, 'min_samples_split': 8}. Best is trial 2 with value: 28041.83268967458.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:12:18,435] Trial 4 finished with value: 28779.415019922384 and parameters: {'n_estimators': 156, 'learning_rate': 0.13910070543154512, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 2 with value: 28041.83268967458.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:12:36,493] Trial 5 finished with value: 29066.865774128662 and parameters: {'n_estimators': 186, 'learning_rate': 0.1726502129517757, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 2 with value: 28041.83268967458.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:12:52,034] Trial 6 finished with value: 29124.12558798919 and parameters: {'n_estimators': 115, 'learning_rate': 0.09265311578731428, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: 28041.83268967458.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:13:07,566] Trial 7 finished with value: 27975.342378866615 and parameters: {'n_estimators': 85, 'learning_rate': 0.07225413688371353, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 7 with value: 27975.342378866615.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:13:23,027] Trial 8 finished with value: 28889.844173206922 and parameters: {'n_estimators': 122, 'learning_rate': 0.14425671729104406, 'max_depth': 8, 'min_samples_split': 3}. Best is trial 7 with value: 27975.342378866615.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:13:38,818] Trial 9 finished with value: 28463.74066767345 and parameters: {'n_estimators': 189, 'learning_rate': 0.09057240912357559, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 7 with value: 27975.342378866615.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:13:54,999] Trial 10 finished with value: 28626.050033161668 and parameters: {'n_estimators': 51, 'learning_rate': 0.055340924765557596, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 7 with value: 27975.342378866615.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:14:10,215] Trial 11 finished with value: 28065.510364331043 and parameters: {'n_estimators': 87, 'learning_rate': 0.05290314554260338, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 7 with value: 27975.342378866615.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:14:25,431] Trial 12 finished with value: 27956.342447296985 and parameters: {'n_estimators': 88, 'learning_rate': 0.10282696370290262, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:14:40,620] Trial 13 finished with value: 27976.463716354854 and parameters: {'n_estimators': 86, 'learning_rate': 0.09251298967407398, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:14:55,518] Trial 14 finished with value: 28191.797370289438 and parameters: {'n_estimators': 87, 'learning_rate': 0.10959423672314744, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:15:10,592] Trial 15 finished with value: 28290.996454382213 and parameters: {'n_estimators': 152, 'learning_rate': 0.07751655263240646, 'max_depth': 6, 'min_samples_split': 5}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:15:25,920] Trial 16 finished with value: 28713.587654726638 and parameters: {'n_estimators': 71, 'learning_rate': 0.1144332921193098, 'max_depth': 7, 'min_samples_split': 8}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:15:43,257] Trial 17 finished with value: 28599.372294295634 and parameters: {'n_estimators': 140, 'learning_rate': 0.07410286245754903, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:16:00,705] Trial 18 finished with value: 28059.096018500077 and parameters: {'n_estimators': 101, 'learning_rate': 0.06743941733913027, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 12 with value: 27956.342447296985.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "[I 2024-11-27 02:16:15,413] Trial 19 finished with value: 28490.684239584996 and parameters: {'n_estimators': 55, 'learning_rate': 0.11411689067754138, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 12 with value: 27956.342447296985.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for the meta-model: {'n_estimators': 88, 'learning_rate': 0.10282696370290262, 'max_depth': 5, 'min_samples_split': 6}\n",
            "Stacked Model RMSE: 27956.342447296985\n",
            "Predictions saved to submission_Stacked_Optimized.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fZkcy19yI9Pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8685764f-d6e3-486b-8427-735d31aec2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed training data shape: (99, 217)\n",
            "Numeric features: Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
            "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
            "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
            "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'PoolQC', 'MiscVal', 'MoSold', 'YrSold'],\n",
            "      dtype='object')\n",
            "Categorical features: Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
            "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
            "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
            "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
            "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
            "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType',\n",
            "       'SaleCondition'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['PoolQC']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load 'train_100' dataset\n",
        "train_100 = pd.read_csv('/content/drive/MyDrive/Masters/ML/train_house_100.csv')\n",
        "X_100 = train_100.drop(\"SalePrice\", axis=1)\n",
        "y_100 = train_100[\"SalePrice\"]\n",
        "\n",
        "# Identify numeric and categorical features in train_100\n",
        "numeric_features_100 = X_100.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features_100 = X_100.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Coerce numeric features to ensure valid data (e.g., replace invalid entries with NaN)\n",
        "for col in numeric_features_100:\n",
        "    X_100[col] = pd.to_numeric(X_100[col], errors='coerce')\n",
        "\n",
        "# Define preprocessing pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing numeric values\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing categorical values\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Define a column transformer for preprocessing\n",
        "preprocessor_100 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features_100),\n",
        "        ('cat', categorical_transformer, categorical_features_100)\n",
        "    ])\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_100_preprocessed = preprocessor_100.fit_transform(X_100)\n",
        "\n",
        "# Inspect transformed data\n",
        "print(f\"Preprocessed training data shape: {X_100_preprocessed.shape}\")\n",
        "print(f\"Numeric features: {numeric_features_100}\")\n",
        "print(f\"Categorical features: {categorical_features_100}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection using SelectFromModel\n",
        "selector_model = RandomForestRegressor(random_state=42)\n",
        "select_from_model = SelectFromModel(selector_model).fit(X_100_preprocessed, y_100)\n",
        "X_100_selected = select_from_model.transform(X_100_preprocessed)\n",
        "\n",
        "# Extract feature names from the preprocessor\n",
        "feature_names = []\n",
        "if hasattr(preprocessor_100, \"transformers_\"):\n",
        "    for name, transformer, columns in preprocessor_100.transformers_:\n",
        "        if name == \"cat\" and hasattr(transformer, \"named_steps\"):\n",
        "            # Get OneHotEncoder feature names for categorical columns\n",
        "            encoder = transformer.named_steps['onehot']\n",
        "            feature_names.extend(encoder.get_feature_names_out(categorical_features_100))\n",
        "        elif name == \"num\":\n",
        "            # Add numeric feature names directly\n",
        "            feature_names.extend(columns)\n",
        "\n",
        "# Get the boolean mask of selected features\n",
        "selected_mask = select_from_model.get_support()\n",
        "\n",
        "# Ensure feature_names and selected_mask have the same length for alignment\n",
        "# This is where the correction is made\n",
        "feature_names = feature_names[1:]\n",
        "\n",
        "# Filter feature names using the boolean mask, but now with aligned lengths\n",
        "selected_features = [feature_names[i] for i in range(len(feature_names)) if selected_mask[i]]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of features before feature selection: {X_100_preprocessed.shape[1]}\")\n",
        "print(f\"Number of features after feature selection: {X_100_selected.shape[1]}\")\n",
        "print(\"Selected features:\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_z0GoRoBTju",
        "outputId": "7122cb07-3771-4d1f-b1d7-a5ffae75f551"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features before feature selection: 217\n",
            "Number of features after feature selection: 23\n",
            "Selected features:\n",
            "['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'BsmtFullBath', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'YrSold', 'LandContour_Lvl', 'ExterQual_TA', 'BsmtQual_Ex', 'BsmtQual_Gd', 'BsmtExposure_Gd', 'GarageFinish_Unf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Feature selection using SequentialFeatureSelector\n",
        "# sequential_selector = SequentialFeatureSelector(selector_model, n_features_to_select=10, direction='forward').fit(X_100_preprocessed, y_100)\n",
        "# X_100_sequential = sequential_selector.transform(X_100_preprocessed)"
      ],
      "metadata": {
        "id": "xozz9-3Mr5Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection using GeneticSelectionCV\n",
        "genetic_selector = GeneticSelectionCV(selector_model, cv=3, verbose=1, scoring=\"neg_mean_squared_error\",\n",
        "                                      n_population=30, n_generations=15, n_gen_no_change=5,\n",
        "                                      crossover_proba=0.5, mutation_proba=0.2, n_jobs=-1)\n",
        "genetic_selector.fit(X_100_preprocessed, y_100)\n",
        "X_100_genetic = genetic_selector.transform(X_100_preprocessed)\n",
        "\n",
        "# Print the number of features before and after feature selection\n",
        "print(f\"Number of features before feature selection: {X_100_preprocessed.shape[1]}\")\n",
        "print(f\"Number of features after feature selection: {X_100_genetic.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yggkwdJjr8SI",
        "outputId": "44dbe17d-41be-4c84-8940-d5d412fdcc0d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting features with genetic algorithm.\n",
            "gen\tnevals\tavg                                        \tstd                                        \tmin                                        \tmax                                        \n",
            "0  \t30    \t[-1.548088e+09  1.177333e+02  6.382145e+08]\t[ 9.099850e+08  5.637135e+01  2.031418e+08]\t[-5.890095e+09  7.000000e+00  3.187650e+08]\t[-1.072906e+09  2.140000e+02  1.324380e+09]\n",
            "1  \t13    \t[-1.198325e+09  1.537000e+02  5.553118e+08]\t[ 1.056010e+08  3.147819e+01  1.159338e+08]\t[-1.463836e+09  9.100000e+01  4.235049e+08]\t[-1.072906e+09  2.100000e+02  9.309154e+08]\n",
            "2  \t25    \t[-1.116979e+09  1.617667e+02  4.740337e+08]\t[ 36924480.880497        25.849156  54810184.562676]\t[-1.191796e+09  1.110000e+02  3.978524e+08]\t[-1.037713e+09  2.090000e+02  6.263155e+08]\n",
            "3  \t16    \t[-1.100868e+09  1.584000e+02  4.516102e+08]\t[ 48195365.339338        20.54199   54341164.329457]\t[-1.252261e+09  1.110000e+02  3.910401e+08]\t[-1.034098e+09  2.090000e+02  5.766080e+08]\n",
            "4  \t17    \t[-1.073107e+09  1.546667e+02  4.273889e+08]\t[ 28876730.85581          9.741093  41609436.426902]\t[-1.133394e+09  1.430000e+02  3.968256e+08]\t[-1.034098e+09  1.990000e+02  5.766080e+08]\n",
            "5  \t17    \t[-1.060089e+09  1.530667e+02  4.184842e+08]\t[ 26166205.165089         5.773118  49332477.143437]\t[-1.140729e+09  1.430000e+02  3.123046e+08]\t[-1.032529e+09  1.690000e+02  6.296975e+08]\n",
            "6  \t13    \t[-1.046665e+09  1.515667e+02  4.010251e+08]\t[ 18742691.793648         3.94701   33644157.723039]\t[-1.104908e+09  1.430000e+02  3.026417e+08]\t[-1.032529e+09  1.650000e+02  4.909616e+08]\n",
            "7  \t16    \t[-1.044396e+09  1.499667e+02  4.011659e+08]\t[ 23907339.33208          2.536183  42722318.791834]\t[-1.134478e+09  1.430000e+02  3.072044e+08]\t[-1.027839e+09  1.540000e+02  5.363152e+08]\n",
            "8  \t17    \t[-1.050821e+09  1.489333e+02  4.023367e+08]\t[ 34844610.268763         3.66909   35634066.871976]\t[-1.159252e+09  1.390000e+02  3.684110e+08]\t[-1.027839e+09  1.540000e+02  5.366541e+08]\n",
            "9  \t12    \t[-1.042044e+09  1.495333e+02  3.909142e+08]\t[ 29222128.12297          2.202019  20931345.750222]\t[-1.139844e+09  1.450000e+02  3.195842e+08]\t[-9.859458e+08  1.510000e+02  4.406697e+08]\n",
            "10 \t19    \t[-1.025036e+09  1.488333e+02  3.649385e+08]\t[ 29341299.945031         2.222361  33454708.187374]\t[-1.085718e+09  1.410000e+02  3.195842e+08]\t[-9.859458e+08  1.510000e+02  4.405187e+08]\n",
            "11 \t16    \t[-1.017955e+09  1.487000e+02  3.578127e+08]\t[ 34295199.137785         1.656301  36950700.562312]\t[-1.117610e+09  1.450000e+02  3.195842e+08]\t[-9.653667e+08  1.520000e+02  4.611580e+08]\n",
            "12 \t12    \t[-9.942539e+08  1.493000e+02  3.342832e+08]\t[ 18304197.53119          1.129897  22666167.097539]\t[-1.040316e+09  1.460000e+02  3.195842e+08]\t[-9.653667e+08  1.530000e+02  3.896312e+08]\n",
            "13 \t22    \t[-9.944171e+08  1.482000e+02  3.367423e+08]\t[ 32342416.766349         2.773686  27950641.764219]\t[-1.141094e+09  1.380000e+02  3.195842e+08]\t[-9.598693e+08  1.510000e+02  4.236208e+08]\n",
            "14 \t16    \t[-9.844717e+08  1.488667e+02  3.365332e+08]\t[ 35727178.791013         2.704728  23043100.528196]\t[-1.140617e+09  1.400000e+02  3.121448e+08]\t[-9.562161e+08  1.520000e+02  4.047784e+08]\n",
            "15 \t13    \t[-9.836269e+08  1.481000e+02  3.391579e+08]\t[ 43585445.433128         3.080584  21575682.657366]\t[-1.160677e+09  1.410000e+02  3.121448e+08]\t[-9.562161e+08  1.520000e+02  3.953270e+08]\n",
            "Number of features before feature selection: 217\n",
            "Number of features after feature selection: 143\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
